{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/bert-base-uncased\"\n",
    "headers = {'Authorization': f\"Bearer {token}\"}\n",
    "def query(payload):\n",
    "  response = requests.post(API_URL, headers=headers, json=payload)\n",
    "  return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.019045086577534676,\n",
       "  'token': 1016,\n",
       "  'token_str': '2',\n",
       "  'sequence': '2 plus 2 is 2.'},\n",
       " {'score': 0.017256537452340126,\n",
       "  'token': 2794,\n",
       "  'token_str': 'added',\n",
       "  'sequence': '2 plus 2 is added.'},\n",
       " {'score': 0.015657629817724228,\n",
       "  'token': 2488,\n",
       "  'token_str': 'better',\n",
       "  'sequence': '2 plus 2 is better.'},\n",
       " {'score': 0.014693384058773518,\n",
       "  'token': 1015,\n",
       "  'token_str': '1',\n",
       "  'sequence': '2 plus 2 is 1.'},\n",
       " {'score': 0.013427536003291607,\n",
       "  'token': 1017,\n",
       "  'token_str': '3',\n",
       "  'sequence': '2 plus 2 is 3.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = query({\"inputs\": \"2 plus 2 is [MASK].\",\n",
    "              \"options\": {\"wait_for_model\": True}})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-cnn\"\n",
    "headers = {'Authorization': f\"Bearer {token}\"}\n",
    "def query(payload):\n",
    "  response = requests.post(API_URL, headers=headers, json=payload)\n",
    "  return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = query(\n",
    "    {\n",
    "        \"inputs\": \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\",\n",
    "        \"parameters\": {\"do_sample\": False},\n",
    "    }\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other tasks include QA, Tabular dataset QA, Text Classification, Text Generation (GPT), Text2Text Generation (Encoder-Decoder architecture), Token Classification: Parsing, Named Entity Recognition,... Translation models, zero-shot classification, Chatbots, Feature Extraction,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_id = 'proj_QSiNYxIySsovHBC5giQfZQ5h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=api_key)\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"write a haiku about ai\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-A5Zn5N8CEw6ku4VFxl74OEn6bUzm5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Silent circuits hum,\\nData streams weave thoughts and dreams,\\nMind born of mere code.', role='assistant', function_call=None, tool_calls=None, refusal=None))], created=1725892583, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_25624ae3a5', usage=CompletionUsage(completion_tokens=17, prompt_tokens=13, total_tokens=30))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Silent circuits hum,\\nData streams weave thoughts and dreams,\\nMind born of mere code.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
