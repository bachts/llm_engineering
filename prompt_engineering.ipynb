{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided response with Outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bach/anaconda3/envs/llm_engineering/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = outlines.models.transformers(\n",
    "    \"gpt2\",\n",
    "    device=\"cuda\"  # optional device argument, default is cpu\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline is a prompt engineering library that can help guide the generation of an LLM with respect to a given structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4 times\n",
      "\n",
      "Answer: 6 times\n",
      "\n",
      "Answer: 10 times\n",
      "\n",
      "\n",
      "2: Go back to your characteristic path, regardless of if you chose to travel further or follow fewer directions, such as following cities such as Aleppo or Baghdad, the character may choose to follow all sectors within the starting point of the door in which the character is flown first, selecting many not least of the ones considered acceptable funding and techniques. As mentioned in the exploit descriptions, falling matter might convey destruction, and the\n"
     ]
    }
   ],
   "source": [
    "generator = outlines.generate.text(model)\n",
    "result = generator(\"Question: What's 2+2? Answer:\", max_tokens=100)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can generate prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please answer the following question following the examples\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "Q: 2+2=?\n",
      "A: 4\n",
      "\n",
      "Q: 3+3=?\n",
      "A: 6\n",
      "\n",
      "Question\n",
      "--------\n",
      "\n",
      "Q: 4+4 = ?\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "@outlines.prompt\n",
    "def few_shots(instructions, examples, question):\n",
    "    \"\"\"{{ instructions }}\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    {% for example in examples %}\n",
    "    Q: {{ example.question }}\n",
    "    A: {{ example.answer }}\n",
    "\n",
    "    {% endfor %}\n",
    "    Question\n",
    "    --------\n",
    "\n",
    "    Q: {{ question }}\n",
    "    A:\n",
    "    \"\"\"\n",
    "\n",
    "instructions = \"Please answer the following question following the examples\"\n",
    "examples = [\n",
    "    {\"question\": \"2+2=?\", \"answer\":4},\n",
    "    {\"question\": \"3+3=?\", \"answer\":6}\n",
    "]\n",
    "question = \"4+4 = ?\"\n",
    "\n",
    "prompt = few_shots(instructions, examples, question)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
